# MLP Results
=== Visualizer Job Starting ===
Node: node19.cluster
Date: Thu Dec  4 09:37:02 CST 2025
Using device: cpu
Loading: ~/fry_program/data/E-5000/5000_E_entities.csv
Embeddings loaded: N=5000, D=300
Loaded embeddings with shape: (5000, 300)

=== INITIAL DIFFERENCE ANALYSIS ===
init difference mean: 5.102040816389943e-08
init difference sd:   3.5351657553721838e-06
vector difference mean: 0.002003646721301859
vector difference sd:   0.10086249949951283
vector cosine difference mean: 0.5324454346153086
vector cosine difference sd:   0.43290843133781415

Number of triplets: 1666
E1 shape: (1666, 300) E2 shape: (1666, 300) E3 shape: (1666, 300)

Train triplets: 1332
Test triplets:  334

=== BASELINE 1: Arithmetic Mean E3 â‰ˆ (E1 + E2) / 2 ===
Train mean cosine: 0.5330691295167065   std: 0.43176166632682933
Test  mean cosine: 0.5299581244097336   std: 0.4374430139047764

=== Training LinearParentToChild ===
Epoch 1/50  Loss=0.015858
Epoch 5/50  Loss=0.007843
Epoch 10/50  Loss=0.006641
Epoch 15/50  Loss=0.006103
Epoch 20/50  Loss=0.005806
Epoch 25/50  Loss=0.005604
Epoch 30/50  Loss=0.005480
Epoch 35/50  Loss=0.005420
Epoch 40/50  Loss=0.005353
Epoch 45/50  Loss=0.005304
Epoch 50/50  Loss=0.005312

=== LinearParentToChild TEST PERFORMANCE ===
Mean MSE: 0.0062611533018449945
Mean cosine: 0.76054883
Std cosine:  0.18659848

=== Training SymmetricMLPParentToChild ===
Epoch 1/80  Loss=0.009250
Epoch 8/80  Loss=0.002486
Epoch 16/80  Loss=0.002450
Epoch 24/80  Loss=0.002452
Epoch 32/80  Loss=0.002455
Epoch 40/80  Loss=0.002442
Epoch 48/80  Loss=0.002446
Epoch 56/80  Loss=0.002435
Epoch 64/80  Loss=0.002449
Epoch 72/80  Loss=0.002437
Epoch 80/80  Loss=0.002434

=== SymmetricMLPParentToChild TEST PERFORMANCE ===
Mean MSE: 0.002623540465719998
Mean cosine: 0.9102798
Std cosine:  0.050190594

================ SUMMARY ================
Baseline mean-of-parents:
  Train cosine: mean=0.5331, std=0.4318
  Test  cosine: mean=0.5300,  std=0.4374

Linear model:
  Test MSE:     0.006261
  Test cosine:  mean=0.7605, std=0.1866

Symmetric MLP model:
  Test MSE:     0.002624
  Test cosine:  mean=0.9103, std=0.0502
=========================================
=== Job Finished ===
Date: Thu Dec  4 09:37:27 CST 2025

# Notes on the chosen MLP

Input: 
- calculate sum of E0 E1
- calulate Hadamard product of E0 E1
- concatenate sum and Hadamard product as x
- this should encode symmetric features e.g. f(E0,E1) = F(E1, E0)

- Input dimension 300
- Hidden layer 512
- Output 300 (predicted E_mean)
- Loss function: MSE

-  Cosine similarity measured between E_mean and E_mean_nn which is generated by the NN 
   from concatenation of the sum and Hadamard product of (E0, E1)
